---
title: "Portland Real Estate Market Statistical Modelling and Analysis (R)"
output:
  html_document:
    df_print: paged
---

```{r cars}
library(ggplot2) # For some amazing looking graphs
library(MASS) # Library for our box-cox transform down the end
library(corrplot) # Plotting nice correlation matrix
library(dplyr) # Library for splitting train & test data set
library(GGally)
library(mctest) #For VIF
library(olsrr) 
library(MASS) #Box-cox
library(lmtest) # Bptest
library(pastecs)
```
## Data Cleaning and Preparation

```{r}
portland = read.csv('C:\\Users\\Chang Sun\\Desktop\\DATA603\\Project\\Portland.csv')
head(portland)
names(portland)
sapply(portland, function(x) sum(is.na(x)))
```
```{r}
#Remove records with NA values
nrow(portland)
portland <- portland[-which(is.na(portland$SQUARE.FEET)),]
nrow(portland)
sapply(portland, function(x) sum(is.na(x)))
```
```{r}
#Extract columns of interest
portland <- portland[,-c(1,3,4,8,10,13,14,15)]
```
```{r}
format((stat.desc(portland)),scientific=F,digits=0)
```
```{r}
#boxplot(PRICE/1000~PROPERTY.TYPE,data = portland,las=2,cex.axis=0.7)
ggplot(portland, aes(x=PROPERTY.TYPE, y=PRICE/1000, fill=PROPERTY.TYPE)) +geom_boxplot() + ggtitle("Price of Different Property Types") +ylab("Price, K")+theme(axis.title.x = element_blank(),axis.text.x = element_text(size = 9,angle = 45),legend.title = element_blank(),legend.position = "none",plot.title = element_text(hjust = 0.5))

par(mfrow = c(3,2))  # Set up a 2 x 2 plotting space
loop.vector <- 1:6 # Create the loop.vector (all the columns)
for (i in 2:ncol(portland)) { # Loop over loop.vector
  # store data in column.i as x
  x <- portland[,i]
    # Plot histogram of x
  hist(x,main = colnames(portland)[i],xlab = colnames(portland)[i],ylab='Frequecny')
}
```
```{r}
#Seperate data to training set and test set
set.seed(2021) 
sample <- sample.int(n = nrow(portland), size = floor(0.8*nrow(portland)), replace = F)
train <- portland[sample, ]
test  <- portland[-sample, ]
head(train)
```
```{r}
ggpairs(train,columns = c(3,4,5,6,7,2), upper = list(continuous = wrap("cor", size = 4)))+ theme_grey(base_size = 8)

plot(train$PRICE, train$SQUARE.FEET, pch = 16, cex = 0.8, col = "blue")
```
```{r}
corPlot <- portland[, c(2,5,3,4,7,6)]
# print the first 6 rows
head(corPlot, 6)
corResult=cor(corPlot, use = "complete.obs")
round(corResult,2)
corrplot(corResult, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)
```

## First Order Model

``` {r}
#Check multicolinearity
fitAllModel <- lm(PRICE~.,data = train)
imcdiag(fitAllModel, method="VIF")
```
```{r}
forwardModel <- ols_step_forward_p(fitAllModel, pent=0.05, details=F)
summary(forwardModel$model)
```
```{r}
backwardModel <- ols_step_backward_p(fitAllModel, prem=0.05, details=F)
summary(backwardModel$model)
```

```{r}
StepwiseModel <- ols_step_both_p(fitAllModel, pent=0.05, prem = 0.05, details=F)
summary(StepwiseModel$model)
```
All methods above select Beds, Baths,Square.feet.
```{r}
allpossible <- ols_step_best_subset(fitAllModel)
Cp <- allpossible$cp
AIC <- allpossible$aic
adjr2 <- allpossible$adjr
cbind(Cp,AIC,adjr2)
allpossible$predictors
```
By comparing Cp, AIC and adjr2 values, model with 4 variables: PROPERTY.TYPE BEDS BATHS SQUARE.FEET is the best.  
```{r}
allposs <- lm(PRICE~PROPERTY.TYPE+SQUARE.FEET+BEDS+ BATHS , data=train)
summary(allposs)
```
Use ANOVA check the significance of Property.Type:
```{r}
anova(backwardModel$model,allposs)
```
Property.Type is not significant, will not be included.
```{r}
summary(fitAllModel)
```
Although automatic variable selection methods did not give DAYS.ON.MARKET as the best variable. Based on common sense, a house tends to sale for a lower price if it stays on market for a long time. Therefore, we decide to add DAYS.ON.MARKET as a predictor. In the end, first order model is: 
```{r}
model_add <- lm(PRICE~(SQUARE.FEET+BEDS+BATHS+DAYS.ON.MARKET),data=train)
summary(model_add)
```

## Interaction Model

```{r}
model_int <- lm(PRICE~(SQUARE.FEET+BEDS+BATHS+DAYS.ON.MARKET)^2,data=train)
summary(model_int)
```
No interaction terms should be added.

## Higher Order Model

```{r}
model_order <- lm(PRICE~SQUARE.FEET+BEDS+BATHS+DAYS.ON.MARKET++I(SQUARE.FEET^2)+I(BEDS^2)+I(BATHS^2)+I(DAYS.ON.MARKET^2),data=train)
summary(model_order)
```
```{r}
model_order <- lm(PRICE~SQUARE.FEET+BEDS+BATHS+DAYS.ON.MARKET+I(SQUARE.FEET^2),data=train)
summary(model_order)
```
P value is significant we have to include the model with higher order terms.

```{r}
anova(model_order,model_add)
```
## MULTIPLE REGRESSION DIAGNOSTICS

### Linearity Assumption

``` {r}
ggplot(model_order, aes(x=.fitted, y=.resid)) +
 geom_point() + geom_smooth()+
 geom_hline(yintercept = 0) 
```
No specific pattern is observed. Smooth line is almost a straight line. Linear assumption is met.  

### Equal Variance Assumption

$H_0$ : Heteroscedasticity is not present (homoscedasticity)
$H_a$ : Heteroscedasticity is present
``` {r}
bptest(model_order)
plot(model_order,3)
```
The p-value = 0.1259 > 0.05, indicating that we failed to reject the null hypothesis.  
Therefore, the test provides evidence to suggest that heteroscedasticity does not exist.

### Normality Assumption
$H_0$ : the sample data are significantly normally distributed
$H_a$ : the sample data are not significantly normally distributed
``` {r}
qplot(residuals(model_order),
 geom="histogram",
 binwidth = 8000,
 main = "Histogram of residuals",
 xlab = "residuals", color="red",
 fill=I("blue"))
```
``` {r}
#normal QQ plot
ggplot(train, aes(sample=model_order$residuals)) +
 stat_qq() +
 stat_qq_line()
```
``` {r}
#Shapiro.Wilk test for Normality
shapiro.test(residuals(model_order))
```
Residuals lines well around the normal distribution straight line.
From the above shapiro-Wilk normality test the p-value = 0.7651 > 0.05 indicates that we failed to reject the null hypothesis.
Thus, confirms that the residuals are normally distributed.

### Multi-Collinearity  
``` {r}
#fitAllModel <- lm(PRICE~.,data = train)
imcdiag(model_order, method="VIF")
```
``` {r}
#fitAllModel <- lm(PRICE~.,data = train)
imcdiag(lm(PRICE~SQUARE.FEET+BEDS+BATHS+DAYS.ON.MARKET,data=train), method="VIF")
```
### Residuals vs Leverage plot

``` {r}
plot(model_order,which=5)
```

### Cookâ€™s Distance

``` {r}
plot(model_order,pch=18,col="red",which=c(4))
```
No data points with Cook's distance>0.5 is observed.

### Leverage points

``` {r}
lev=hatvalues(model_order)
p = length(coef(model_order))
n = nrow(train)

print("** 2p/n Outliers **")
outlier2p = lev[lev>(2*p/n)]
print(outlier2p)
print("                   ")
print("                   ")
print("** 3p/n Outliers **")
outlier3p = lev[lev>(3*p/n)]
print(outlier3p)

```

``` {r}
plot(rownames(train),lev, main = "Leverage in Portland Dataset",
xlab="observation",
 ylab = "Leverage Value")
abline(h = 2 *p/n, lty = 1)
abline(h = 3 *p/n, lty = 1)
```

``` {r}
# Remove leverage>2*p/n points
train[which(hatvalues(model_order) > 2 *p/n),]

new_train_1 <- train[-which(hatvalues(model_order) > 2 *p/n),]

str(new_train_1)
```

``` {r}
# Remove leverage>3*p/n points
train[which(hatvalues(model_order) > 3 *p/n),]

new_train_2 <- train[-which(hatvalues(model_order) > 3 *p/n),]

str(new_train_2)
```

``` {r}
#Use data removed leverage>2p/n to fit the model
model_order_no_2p <- lm(PRICE~SQUARE.FEET+BEDS+BATHS+DAYS.ON.MARKET+I(SQUARE.FEET^2),data=new_train_1)
summary(model_order_no_2p)
```

``` {r}
#Use data removed leverage>3p/n to fit the model
model_order_no_3p <- lm(PRICE~SQUARE.FEET+BEDS+BATHS+DAYS.ON.MARKET+I(SQUARE.FEET^2),data=new_train_2)
summary(model_order_no_3p)
```
Using data sets removed points with leverage 2*p/n and 3*p/n give lower adj-R2 than original train data. Will keep the high leverage points.

## Prediction

``` {r}
predict20 = predict.lm(model_order, newdata=test)

plot(PRICE~BEDS, data = test, col="red", pch=19, main="Actual vs Predicted")
points(test$BEDS, predict20, col="blue", pch=22)
legend("topleft", legend=c("Actual", "Predicted"), col=c("red", "blue"), pch=c(19,22), cex = 0.8)

plot(PRICE~SQUARE.FEET, data = test, col="red", pch=19, main="Actual vs Predicted")
points(test$SQUARE.FEET, predict20, col="blue", pch=22)
legend("topleft", legend=c("Actual", "Predicted"), col=c("red", "blue"), pch=c(19,22), cex = 0.8)

plot(PRICE~BATHS, data = test, col="red", pch=19, main="Actual vs Predicted")
points(test$BATHS, predict20, col="blue", pch=22)
legend("topleft", legend=c("Actual", "Predicted"), col=c("red", "blue"), pch=c(19,22), cex = 0.8)

plot(PRICE~DAYS.ON.MARKET, data = test, col="red", pch=19, main="Actual vs Predicted")
points(test$DAYS.ON.MARKET, predict20, col="blue", pch=22)
legend("topright", legend=c("Actual", "Predicted"), col=c("red", "blue"), pch=c(19,22), cex = 0.8)

plot(predict20, test$PRICE, main="Predicted Price vs Actual Price", xlab="Predicted Price", ylab="Actual Price")
abline(a=0, b=1)
```

``` {r}
mape = mean(abs((test$PRICE - predict20)/test$PRICE))

predict20pred = predict.lm(model_order, newdata=test, level=0.95, interval = "prediction")

matplot(test$BEDS, predict20pred, pch=c(22, 2, 6), col=c("blue", "green", "brown"), main="95% Prediction Intervals", xlab="BEDS (Bedroom Number)", ylab="Price ($)")
points(test$BEDS, test$PRICE, col="yellow2", pch=19)
legend ("bottomright", legend=c ("Predicted", "Lowlimite", "Uplimite", "Actual"),
col=c("blue", "green", "brown", "yellow2"), pch=c(22, 2, 6, 19), cex=0.8) 

matplot(test$SQUARE.FEET, predict20pred, pch=c(22, 2, 6), col=c("blue", "green", "brown"), main="95% Prediction Intervals", xlab="SQUARE.FEET", ylab="Price ($)")
points(test$SQUARE.FEET, test$PRICE, col="yellow2", pch=19)
legend ("bottomright", legend=c ("Predicted", "Lowlimite", "Uplimite", "Actual"),
col=c("blue", "green", "brown", "yellow2"), pch=c(22, 2, 6, 19), cex=0.8) 

matplot(test$BATHS, predict20pred, pch=c(22, 2, 6), col=c("blue", "green", "brown"), main="95% Prediction Intervals", xlab="BATHS (Bath Number)", ylab="Price ($)")
points(test$BATHS, test$PRICE, col="yellow2", pch=19)
legend ("bottomright", legend=c ("Predicted", "Lowlimite", "Uplimite", "Actual"),
col=c("blue", "green", "brown", "yellow2"), pch=c(22, 2, 6, 19), cex=0.8) 

matplot(test$DAYS.ON.MARKET, predict20pred, pch=c(22, 2, 6), col=c("blue", "green", "brown"), main="95% Prediction Intervals", xlab="DAYS.ON.MARKET (Days)", ylab="Price ($)")
points(test$DAYS.ON.MARKET, test$PRICE, col="yellow2", pch=19)
legend ("topright", legend=c ("Predicted", "Lowlimite", "Uplimite", "Actual"),
col=c("blue", "green", "brown", "yellow2"), pch=c(22, 2, 6, 19), cex=0.8) 

```
Predicted Price vs. Actual Price sit along the straight line with slope=1.  
Actual price fall between the upper and lower limit of 95% confidence interval.
